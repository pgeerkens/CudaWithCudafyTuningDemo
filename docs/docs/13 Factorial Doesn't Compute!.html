<div class="wikidoc">
<p>Twelve factorial amounts to just under 500,000,000, so multiplying that by 13 is greater than Int32.MaxValue, and even UInt32.MaxValue. To analyze further it is necessary to employ Int64 values for Permutations and Permutation, which is investigated in GpuTsp4*.cs.&nbsp;
 As shown here though, we get a performanc shock when we run these cases:</p>
<pre>x64 Release ( 128 threads_per * 768 blocks = 98304 threads)
Cities  12;   Permutations:  479001600:
---------------------------------------
... and now with disk cache populated.
           Total     Load      Run
              ms       ms       ms  distance
GpuTsp3     3301 =     93 &#43;   3208; 111.3318: - 3_Architecture_x64_2_1
GpuTsp3a    2308 =     98 &#43;   2210; 111.3318: - 3_PathArrayStrided
GpuTsp3b    2328 =    101 &#43;   2227; 111.3318: - 3_DivisorsCachedGlobal

GpuTsp4     8953 =    100 &#43;   8853; 111.3318: - 4_Long
GpuTsp4a    7841 =    103 &#43;   7738; 111.3318: - 4_PathArrayStrided
GpuTsp4b    6643 =    100 &#43;   6543; 111.3318: - 4_DivisorsCachedGlobal
</pre>
<p>Even <em>Striding</em> the <em>path </em>array only provides marginal improvemnt for the *3 performance hit from expanding fromInt32 to Int64; both less marginal and less relative improvement thatn it provided for Int32. What has gone wrong?</p>
<p>The answer lies in the extremely trim architecture of the GPU's themselves, focussed on fast single-precision floating-point calculations. After much investigation, it turns out that the offending code is
<strong>a single line</strong> in the implementation of <em>PathFromRoutePermutation</em>, bolded below:</p>
<div style="color:black; background-color:white">
<pre>[Cudafy]
<span style="color:blue">public</span> <span style="color:blue">static</span> <span style="color:blue">float</span> PathFromRoutePermutation(GThread thread, 
				<span style="color:blue">long</span>  permutations, <span style="color:blue">long</span>  permutation, <span style="color:blue">int</span>[,] path) {
   <span style="color:blue">for</span> (<span style="color:blue">int</span> city = 0; city &lt; _cities; city&#43;&#43;) { path[city, thread.threadIdx.x] = city; }

   <span style="color:green">// Credit: SpaceRat. </span>
   <span style="color:green">// http://www.daniweb.com/software-development/cpp/code/274075/all-permutations-non-recursive</span>
   <span style="color:blue">var</span> divisor = permutations;
   <span style="color:blue">for</span> (<span style="color:blue">int</span> city = _cities; city &gt; 1L; <span style="color:green">/* decrement in loop body */</span>) {
      <strong>divisor	/= city;
</strong>      <span style="color:blue">int</span> dest	= (<span style="color:blue">int</span>)((permutation / divisor) % city);

   city--;

      <span style="color:blue">var</span> swap				= path[dest, thread.threadIdx.x];
      path[dest, thread.threadIdx.x]	= path[city, thread.threadIdx.x];
      path[city, thread.threadIdx.x]	= swap;
   }
   <span style="color:blue">return</span> 0;
}</pre>
</div>
<p>The calculation of <em>divisor </em>is a killer because <strong><em>there is absolutely no hardware support for 64-bit integer division on NVIDIA GPU's at this time.</em></strong></p>
<p>But after a good night's rest I remembered Rule #1:</p>
<p><a href="http://cudafytuningtutorial.codeplex.com/wikipage?title=Never%20Divide%20When%20You%20Can%20Multiply%20Instead%21">Never Divide When You Can Multiply Instead!</a></p>
</div><div class="ClearBoth"></div>