<div class="wikidoc">
<p>First, we will review our code foundation and cover some odds and ends.</p>
<ul>
<li>A careless error in John's distance formula has been corrected - I won't embarass him anymore than that.
</li><li>In the original MPU code a lock is unnecessarily held in the main calculation loop. The
<em>MpuTsp_Better </em>class corrects that error with this improved loop: </li></ul>
<div style="color:black; background-color:white">
<pre style="padding-left:60px">Parallel.For(0, _permutations, 
   () =&gt; <span style="color:blue">new</span> LocalData(<span style="color:blue">float</span>.MaxValue, -1L),
   (permutation, state, localData) =&gt; {
      <span style="color:blue">var</span> path		= <span style="color:blue">new</span> <span style="color:blue">int</span>[1, _cities];
      <span style="color:blue">var</span> distance	= FindPathDistance( permutation, path, 0);
      <span style="color:blue">if</span> (distance &lt; localData.BestDistance) {
         localData.BestDistance		= distance;
         localData.BestPermutation	= permutation;
      }
      <span style="color:blue">return</span> localData;
   },
   (localData) =&gt; {
      <span style="color:blue">lock</span> (locker) { 
         <span style="color:blue">if</span> (localData.BestDistance &lt; bestDistance) {
            bestDistance	= localData.BestDistance;
            bestPermutation	= localData.BestPermutation;
         }
      }
   }
);</pre>
</div>
<p style="padding-left:30px">I was surprised at how litle improvement that made in the timing on an 8-core system. This is our new comparison base for the advantages of GPU-enabled algorithms.</p>
<ul>
<li>Notice the times and timing changes for <em>GpuTsp0</em>-<em>cold </em>and -<em>warm</em>; this is the identical code run twice in succession. I left the first&nbsp;in to warm-up the GPU, and JIT-compile the
<strong>CUDA </strong>and <strong>CUDAfy</strong>, so we can get a better comparison against the time for&nbsp;<em>GpuTsp</em>-warm.
</li><li>The large load times for the first run of each test is for compiling and CUDAfy-ing the tests. In production this time would be eliminated by caching the result, as seen in the second time for each test.
</li></ul>
<p>Next: <a href="http://cudafytuningtutorial.codeplex.com/wikipage?title=Structs%20%26%20Strides%20-%20Basic%20GPU%20memory%20access">
Structs &amp; Strides - Basic GPU Memory Access</a></p>
<p>&nbsp;</p>
</div><div class="ClearBoth"></div>